# DM

# 1 概述

数据挖掘定义：从海量数据中抽取感兴趣的模式和知识的过程；从存放在数据库、数据仓库中或其他信息库中的大量数据中挖掘有趣知识的过程。

:rocket: 数据挖掘步骤： :rocket:

（1）准备数据集

> 可以从传统数据库，数据仓库或平面文件中获取

（2）选择数据挖掘算法，进行数据挖掘

（3）解释和评估

（4）模型应用

---

机器学习的分类：监督学习，无监督学习，半监督学习，主动学习

半监督学习：半监督学习使用大量的未标记数据，以及同时使用标记数据，来进行数据挖掘工作。标记的实例用来学习模型，未标记的数据用来改进类边界。

主动学习：主动学习通过一定的算法查询**最有用的未标记样本**，并交由专家进行标记，然后用查询到的样本训练分类模型来提高模型的精确度

# 2 认识数据

## 2.1 数据对象与属性类型

属性（维度，特征，变量）：一个数据字段，表示一个数据对象的某个特征。

> 类型有：标称属性，二元属性，序列属性，数值属性

枚举或标称属性：能够用有限个元素对属性进行描述的集合。如`头发颜色 = {黑色，棕色，灰色，淡黄色}`

二值属性：只有两个状态的枚举属性。

序列属性：值的顺序具有意义的属性。如`尺寸 = {小，中，大}，成绩`等

数值属性：可用整数或实数进行度量的属性。如`身高，体重，收入`

> 区间标度属性：使用相等的单位尺度度量，可以定量评估属性值的差
>
> - 取值有顺序（如摄氏度和华氏度）
> - 没有真实零点
>
> 比率标度属性：具有固定零点的数值属性，如工作年限，重量，高度等

同时属性也可分为：**离散属性和连续属性**

---

数据的计量尺度：（由低级到高级）

定类尺度：按照事物的某种属性对其进行平行的分类或分组，如性别（男，女）

> - 具有 $=$ 和 $\neq$ 的数学特性
> - 数据表现为类别

定序尺度：是对事物之间等级和顺序差别之间的一种测度，如产品等级（一等品，二等品）

> - 具有 $<$ 和 $>$ 的数学特性
> - 数据表现为类别，但有序

定距尺度（间隔尺度）：是对事物类别或次序之间的间距的测度，如100分制考试成绩

> - 具有 $+$ 和 $-$ 的数学特性
> - 可排序，也可指出类别之间的差距
> - 没有绝对零点（`0是测量尺度上的一个测量点，并不代表没有`）

定比尺度：能够测量两个测度值之间比值的一种计量尺度。如职工月收入，企业产值

> - 除具备上述三种的所有特点外，还可计算两个测度值之间的比值
> - 有绝对零点
> - 具有 $+ - \times \div$ 的数学特性

![](https://image3.slideserve.com/6232486/slide9-l.jpg)

## 2.2 数据的基本统计描述

中心趋势度量：均值，中位数，众数，中列数

数据的散布：极差，四分位数，方差，标准差，四位数极差

### 2.2.1 中心趋势度量

样本平均数：（样本均值是一个无偏估计量，所以分母就是 $n$ ）
$$
\bar x = \dfrac{x_1 + x_2 + \cdots + x_n}{n} = \frac{\sum \limits_{i = 1}^n x_i}{n}
$$
总体平均数：
$$
\mu = \dfrac{x_1 + x_2 + \cdots + x_N}{N} = \frac{\sum \limits_{i = 1} ^ N x_i}{N}
$$
![](https://img-blog.csdnimg.cn/262e061ad8ee4d708c58d50324a864c9.png)

- 易受极端值影响
- 数据对称分布或接近对称分布时应用

---

中位数：
$$
M_e = 
\begin{cases}
X_{\frac{N + 1}{2}}, & N为奇数 \\
\frac{1}{2} (X_{\frac{N}{2}} + X_{\frac{N}{2} + 1}), & N为偶数
\end{cases}
$$

- 数据分布偏斜成都较大时应用

---

众数：出现次数最多的数

- 不受极端值的影响
- 可能没有众数或有多个众数
- 数据分布偏斜程度较大且有明显峰值时应用

---

中列数：数据集中最大最小值的平均值 $(max + min) / 2$

![](https://pica.zhimg.com/80/v2-07a1c6f39275bdb582d0b455fa140095_1440w.webp?source=1940ef5c)

### 2.2.2 散布度量

极差：最大值与最小值之差

> - 离散程度的最简单测度值
>
> - 易受极端值影响
>
> - 未考虑数据的分布

分位数：数据分布的每隔一定间隔的点。如四分位数，分别为 $Q_1$ ，中位数，$Q_3$ 
$$
1. &
\begin{cases}
Q_1 = \frac{n}{4} \\
Q_3 = \frac{3n}{4}
\end{cases} \\
2. &
\begin{cases}
Q_1 = \frac{n + 1}{4} \\
Q_3 = \frac{3(n + 1)}{4}
\end{cases}
$$
四分位数极差：$IQR=Q_3-Q_1$ 

>- 不受极端值影响

方差和标准差：
$$
总体方差：\sigma ^ 2 = \frac{\sum \limits _{i = 1} ^ N (x_i - \mu) ^ 2}{N} & 总体标准差：\sigma \\
样本方差：s ^ 2 = \frac{\sum \limits_{i = 1} ^ n (x_i - \bar x) ^ 2}{n - 1} & 样本标准差： s
$$


> 总体：研究对象的全体
>
> 样本：从总体中随机抽取的部分观察单位
>
> 样本方差分母为何要是 $n - 1$ ，证明：[https://blog.csdn.net/Hearthougan/article/details/77859173](https://blog.csdn.net/Hearthougan/article/details/77859173) ，要保证样本方差是总体方差的一个无偏估计

### 2.2.3 图形显示

#### 2.2.3.1 盒图

由一个箱子，两条线段组成

5个特征值：最大值，最小值，中位数Me，两个四分位数$Q_L, Q_R$

最小值：$Q_L - 1.5 \times IQR$

最大值：$Q_R + 1.5 \times IQR$

> 在 $[Q_L - 1.5 \times IQR, Q_R + 1.5 \times IQR]$ 范围外的视为异常值，不用做最大最小值

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8yMjUwNzc0MC1hY2I5NGMzNTc3NmFlNzE0LnBuZw?x-oss-process=image/format,png)

#### 2.2.3.2 直方图

直方图相比盒图能描述更多的数据细节

![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Histogram_example.svg/220px-Histogram_example.svg.png)

#### 2.2.3.3 分位数图

是一种观察单变量数据分布的方法，描绘出了分位数信息。

#### 2.2.3.4 分位数-分位数图

 是一种衡量单变量的不同分布之间的对比情况。

#### 2.2.3.5 散点图

是一种确定两个变量之间是否存在联系、模式或趋势的图形方法。

有正相关，负相关，线性无关三种情况

## 2.3 数据可视化

- 基于像素的可视化

- 几何投影可视化
- 散点图矩阵

- 基于图符的可视化

- 层次可视化

- 可视化复杂对象和关系

## 2.4 数据相似度和相异度的度量

相似性，相异性，邻近性（相似性或相异性都称为邻近性）

### 2.4.1 枚举属性的相邻性度量

相异性矩阵：

![](https://img-blog.csdn.net/20151206170425301)

**标称（枚举）属性**之间的相异性：标称属性的状态数为 $M$ ， 数据对象 $i$ 和 $j$ 之间的相异性为
$$
d(i, j) = \frac{p - m}{p},m为匹配的数目，p是对象的属性总数
$$
相似性计算为：
$$
sim(i, j) = 1 - d(i, j) = \frac{m}{p}
$$

### 2.4.2 二元属性的相邻性度量

二元属性的相异性：

![](https://mmbiz.qpic.cn/mmbiz_png/roPWrjQ5nUGibUbuNn04cAdSxIfrpNroQsjbebFMOjh8ibLM7hiaPKWBCZmU0Hf2ypqTm7z89bvmticb0eo5mLHpEQ/640?wx_fmt=png)

数据对象 $i$ 和 $j$ 的相异性：
$$
d(i, j) = \frac{r + s}{q + r + s + t}
$$
非对称的二元相异性：
$$
d(i, j) = \frac{r + s}{q + r + s}
$$
非对称的二元相似性（又称为Jaccard系数）
$$
sim(i, j) = \frac{q}{q + r + s} = 1 - d(i, j)
$$

### 2.4.3 数据的相异性

度量标准通常有两种：**距离和相似性系数**

距离度量方法：欧几里得距离，切比雪夫距离，曼哈顿距离，闵科夫斯基距离，兰氏距离

欧几里得距离：
$$
二维空间：d = \sqrt{(x_1 - x_2) ^ 2 + (y_1 - y_2) ^ 2}
$$
切比雪夫距离：
$$
二维空间：d = max(|x_1 - x_2|, |y_1 - y_2|)
$$
曼哈顿距离：
$$
二维空间：d = |x_1  - x_2| + |y_1 - y_2|
$$
闵科夫斯基距离：（闵科夫斯基距离不是一种距离，而是一组距离的定义）

对数据量纲敏感，一般需要进行数据的标准化。
$$
i = (x_{i1}, x_{i2}, \cdots, x_{ip}), j = (x_{j1}, x_{j2}, \cdots, x_{jp}) \\
d(i, j) = \sqrt[h]{|x_{i1} - x_{j1}| ^ h + \cdots + |x_{ip} - x_{jp}| ^ h}
$$
兰氏距离：（被称为马氏距离的加权版本，对数据的量纲不敏感）
$$
d(x, y) = \sum \limits _{i = 1} ^ n \frac{|x_i - y_i|}{|x_i| + |y_i|}
$$

### 2.4.4 序数属性的邻近性度量

将序数属性中的值按序映射为对应的值

### 2.4.5 混合属性的邻近性度量

余弦相似性：
$$
x = (x_1, x_2, \cdots, x_p), y = (y_1, y_2, \cdots, y_p) \\
sim(x, y) = \frac{x \cdot y}{||x|| \ ||y||} = \frac{x_1y_1 + \cdots + x_py_p}{\sqrt{x_1^2 + \cdots + x_p^2} \sqrt{y_1^2 + \cdots + y_p^2}}
$$
余弦值越接近1，夹角越小，向量之间匹配越大

![image-20230617210814137](DM/image-20230617210814137.png)
